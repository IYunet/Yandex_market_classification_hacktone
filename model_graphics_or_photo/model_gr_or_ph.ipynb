{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f94af6",
   "metadata": {
    "cellId": "46wez4bmsx2c6551rtf1c",
    "execution_id": "e212b825-9f6c-4a1f-8e20-448d70ff4a7e"
   },
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462a55b4",
   "metadata": {
    "cellId": "f98v3ko7eanm2bxe3r6h",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /tmp/xdg_cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      "100%|██████████| 528M/528M [00:06<00:00, 83.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "import torch.nn.init as init\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torchvision.models import VGG16_BN_Weights, vgg16_bn\n",
    "\n",
    "weights = VGG16_BN_Weights.DEFAULT\n",
    "model = vgg16_bn(weights=weights)\n",
    "transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b702dc0d",
   "metadata": {
    "cellId": "rwa4lncgk18x7p0c5cgfq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "class goodsDataset(Dataset):\n",
    "    LABELS = {\n",
    "        \"clean_photo\": 0,\n",
    "        \"infographics\": 1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, df, label_column_name, path_column_name, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            df : pandas DataFrame.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = df\n",
    "        self.label_column_name = label_column_name\n",
    "        self.path_column_name = path_column_name\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        try:\n",
    "            path = self.data_frame[[self.path_column_name]].iloc[idx][0]\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"произошла ошибка в goodsDataset при загрузки картинки: {e}\")\n",
    "\n",
    "        label = torch.tensor(\n",
    "            goodsDataset.LABELS[\n",
    "                self.data_frame[[self.label_column_name]].iloc[idx][0]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        sample = [image, label]\n",
    "        return sample\n",
    "\n",
    "\n",
    "def load_data(df, transform, label_column_name, path_column_name, batch_size=4, num_workers=0, shuffle=True):\n",
    "    goods_dataset = goodsDataset(df=df, label_column_name=label_column_name, transform=transform, path_column_name=path_column_name)\n",
    "    dataloader = DataLoader(\n",
    "        goods_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, test_losses, train_accuracies, test_accuracies):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n",
    "    axs[0].plot(range(1, len(test_losses) + 1), test_losses, label='test')\n",
    "    axs[0].set_ylabel('loss')\n",
    "\n",
    "    axs[1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train')\n",
    "    axs[1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test')\n",
    "    axs[1].set_ylabel('accuracy')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                train_loader,\n",
    "                test_loader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                NUM_EPOCHS,\n",
    "                name_file_save,\n",
    "                device='cpu',\n",
    "                scheduler=None,\n",
    "                save=True):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    best_accuracy = 0.0\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_loader, desc='Training'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # images: batch_size x num_channels x height x width\n",
    "            logits = model(images)\n",
    "            # logits: batch_size x num_classes\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.shape[0]\n",
    "            train_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy /= len(train_loader.dataset)\n",
    "        train_losses += [train_loss]\n",
    "        train_accuracies += [train_accuracy]\n",
    "\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), name_file_save + '.pth')\n",
    "\n",
    "        true_label = np.array([])\n",
    "        predict_label = np.array([])\n",
    "        test_loss, test_accuracy = 0.0, 0.0\n",
    "        model.eval()\n",
    "        for images, labels in tqdm(test_loader, desc='Validating'):\n",
    "            true_label = np.append(true_label, labels.cpu().numpy())\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(images)\n",
    "                # logits: batch_size x num_classes\n",
    "                loss = criterion(logits, labels)\n",
    "                probabilities = torch.softmax(logits, dim=1)  # Преобразование логитов в вероятности\n",
    "                predicted_class = torch.argmax(probabilities, dim=1)\n",
    "                predict_label = np.append(predict_label, predicted_class.cpu().numpy())\n",
    "\n",
    "            test_loss += loss.item() * images.shape[0]\n",
    "            test_accuracy += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy /= len(test_loader.dataset)\n",
    "        test_losses += [test_loss]\n",
    "        test_accuracies += [test_accuracy]\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        model.load_state_dict(best_weights)\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), name_file_save + '.pth')\n",
    "\n",
    "        plot_losses(train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "        print(classification_report(true_label, predict_label))\n",
    "\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c0c0fe",
   "metadata": {
    "cellId": "vsi8ukyowjrqmoctknanl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "\n",
    "df = pd.read_csv(\"data_for_binary.csv\")\n",
    "label_column_name = \"verdict\"\n",
    "path_column_name = \"path\"\n",
    "\n",
    "train, test = train_test_split(\n",
    "    df[[path_column_name, label_column_name]], \n",
    "    random_state=42, \n",
    "    test_size=0.2)\n",
    "\n",
    "train_loader = load_data(\n",
    "    train, transform, \n",
    "    label_column_name, \n",
    "    path_column_name, \n",
    "    batch_size=20)\n",
    "\n",
    "test_loader = load_data(\n",
    "    test, \n",
    "    transform, \n",
    "    label_column_name, \n",
    "    path_column_name, \n",
    "    batch_size=20, \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78410756",
   "metadata": {
    "cellId": "zlrgevjzsy1z68cqekiyw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=100, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Замораживаем все слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Размораживаем параметры последнего полносвязанного слоя (classifier)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "num_classes = 2\n",
    "num_neuron = 512\n",
    "# model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 100),\n",
    "    nn.Softmax(),\n",
    "    nn.Linear(100, 2)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        init.xavier_uniform_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            init.constant_(layer.bias, 0)\n",
    "\n",
    "# Применяем инициализацию ко всем слоям внутри nn.Sequential\n",
    "model.classifier.apply(initialize_weights)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c76a7-2772-4a76-bfd6-4d6fcda89828",
   "metadata": {},
   "source": [
    "Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66231c",
   "metadata": {
    "cellId": "4up2blpmc7f05ayl7nm3h6p"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "NUM_EPOCHS = 7 # 40 = 40\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=0.001, weight_decay=0.01, fused=True)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=0, verbose=True)\n",
    "name_file_save = \"model_gr_or_ph\"\n",
    "\n",
    "\n",
    "train_losses, train_accuracies, test_losses, test_accuracies = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    NUM_EPOCHS,\n",
    "    name_file_save,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc371e-d540-4aaa-a549-fb3b5050ae46",
   "metadata": {},
   "source": [
    "Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad33b76",
   "metadata": {
    "cellId": "c5qd35cxec8rrtr0yzil"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Замораживаем все слои\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True # torch.rand(1).item() < 0.3\n",
    "\n",
    "# Размораживаем параметры последнего полносвязанного слоя (classifier)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_classes = 2\n",
    "num_neuron = 512\n",
    "# model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 100),\n",
    "    nn.Softmax(),\n",
    "    nn.Linear(100, 2)\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('model_gr_or_ph.pth', map_location=torch.device(device)))\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "NUM_EPOCHS = 100 # 40 = 40\n",
    "\n",
    "# optimizer = torch.optim.NAdam(model.parameters(), lr=0.002, weight_decay=0.01)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.002, verbose=True, weight_decay=0.2)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01, fused=True)\n",
    "\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.02, verbose=True)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-4, verbose=True)\n",
    "name_file_save = \"model_gr_or_ph\"\n",
    "\n",
    "\n",
    "train_losses, train_accuracies, test_losses, test_accuracies = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    NUM_EPOCHS,\n",
    "    name_file_save,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    save=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notebookId": "cac33ab2-af36-46e3-b506-4857b9d24b43",
  "notebookPath": "model_graphics_or_photo/model_gr_or_ph.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
